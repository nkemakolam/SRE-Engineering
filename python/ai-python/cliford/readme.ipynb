{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Required Libraries:\n",
    "First, make sure you have the required libraries installed. For this example, we'll use the epublib library to parse the EPUB file and spaCy for Named Entity Recognition (NER). Install them using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "## first install nltk library\n",
    " run python -m pip install nltk \n",
    " run python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# on the python termianl you run these following prompts\n",
    ">>> from nltk.tokenize import word_tokenize\n",
    ">>> s = '''Good muffins cost $3.88\\nin New York.  Please buy me ... two of them.\\n\\nThanks.'''\n",
    ">>> word_tokenize(s) \n",
    ">>> from nltk.tokenize import wordpunct_tokenize\n",
    ">>> wordpunct_tokenize(s) \n",
    ">>> from nltk.tokenize import sent_tokenize, word_tokenize\n",
    ">>> sent_tokenize(s)\n",
    ">>> [word_tokenize(t) for t in sent_tokenize(s)] \n",
    ">>> from nltk.tokenize import WhitespaceTokenizer\n",
    ">>> list(WhitespaceTokenizer().span_tokenize(s))\n",
    "\n",
    "## url https://www.nltk.org/api/nltk.tokenize.html"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
